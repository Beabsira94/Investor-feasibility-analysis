{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage we are going to proceed with a deeper level of user experience analysis. We are going to focus on one of the great revolution of the last decade, Mobile devices. The success for mobile devices has been heavily dependent on their customers. We are going to track and evaluate the customer’s experience to better understand their requirements and needs. \n",
    "In the telecom industry the User experience is mostly related to Network parameter performances or the customers’ device characteristics. \n",
    "So our focus is going to be on analyzing network parameters like\n",
    "•\tTCP retransmission\n",
    "•\tRound trip time(RTT)\n",
    "•\tThroughput\n",
    "•\tFinally customer devices characteristics like handset type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to breakdown the task into different phases so as to make the work efficient and more comprehensible. The phases go as follows:  \n",
    " ### Phase 1: Data Preparation  \n",
    "  - Aggregate, per customer, the following information:\n",
    "    - Average TCP retransmission\n",
    "    - Average RTT\n",
    "    - Handset type\n",
    "    - Average throughput\n",
    "  - Handle missing data and outliers by replacing with the mean or mode of the corresponding variable.(Re-use the code for data cleaning in the other notebooks)\n",
    "\n",
    " ### Phase 2: Exploratory Data Analysis (EDA)  \n",
    "  - Compute & list 10 of the top, bottom, and most frequent:\n",
    "    - TCP values in the dataset.\n",
    "    - RTT values in the dataset.\n",
    "    - Throughput values in the dataset.\n",
    "\n",
    " ### Phase 3: Feature Analysis and Interpretation  \n",
    "  - Compute & report:\n",
    "    - The distribution of the average throughput per handset type and provide an interpretation of the findings.\n",
    "    - The average TCP retransmission view per handset type and provide an interpretation of the findings.\n",
    "\n",
    " ### Phase 4: Modeling  \n",
    "  - Using the experience metrics above, perform k-means clustering (where k = 3) to segment users into groups of experiences and provide a brief description of each cluster. The description should define each group based on your understanding of the data.\n",
    "\n",
    " ### Phase 5: Dashboard Development  \n",
    "  - Design and develop a dashboard using visualization tools to visualize data insights.\n",
    "\n",
    " Explanation\n",
    "- Phase 1: Data Preparation focuses on cleaning the dataset and computing necessary aggregates.\n",
    "- Phase 2: EDA involves exploring the data to understand its distribution and key characteristics.\n",
    "- Phase 3: Feature Analysis and Interpretation requires detailed analysis and interpretation of specific variables and patterns within the dataset.\n",
    "- Phase 4: Modeling involves applying machine learning techniques to segment users.\n",
    "- Phase 5: Dashboard Development is dedicated to visualizing the insights obtained from the previous phases in a user-friendly format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 Data preparation  \n",
    "In this phase we are going to re-use the code in the other notebooks to prepare and clean the data. After that we are going to compute valuse like average TCP retransmission, average RTT, handset type, and average throughput. We first start by loading and cleaning the data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\beab\\desktop\\kifiya aim\\investor-feasibility-analysis\\venv\\lib\\site-packages (2.9.9)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\beab\\desktop\\kifiya aim\\investor-feasibility-analysis\\venv\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\beab\\desktop\\kifiya aim\\investor-feasibility-analysis\\venv\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\beab\\desktop\\kifiya aim\\investor-feasibility-analysis\\venv\\lib\\site-packages (from sqlalchemy) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_data_from_postgres, load_data_using_sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Beab\\Desktop\\Kifiya AIM\\Investor-feasibility-analysis\\scripts\\load_data.py:38: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the data\n"
     ]
    }
   ],
   "source": [
    "# Define your SQL query\n",
    "query = \"SELECT * FROM xdr_data;\"  # Replace with your actual table name\n",
    "\n",
    "# Load data from PostgreSQL\n",
    "df = load_data_from_postgres(query)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "if df is not None:\n",
    "    print(\"Successfully loaded the data\")\n",
    "else:\n",
    "    print(\"Failed to load data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before outlier removal: 150001\n",
      "Number of rows after outlier removal: 150001\n",
      "\n",
      "Total number of outliers removed: 451082\n",
      "\n",
      "First few rows of the DataFrame with outliers removed:\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0    86399.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1    86399.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2    86399.0  2.082015e+14   3.366371e+10  3.528151e+13   \n",
      "3    86399.0  2.082014e+14   3.366371e+10  3.535661e+13   \n",
      "4    86399.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Display the number of rows before outlier removal\n",
    "print(f\"Number of rows before outlier removal: {df.shape[0]}\")\n",
    "\n",
    "# Function to identify and replace outliers using IQR method\n",
    "def handle_outliers_iqr(df):\n",
    "    df_cleaned = df.copy()  # Create a copy of the DataFrame for modifications\n",
    "    outlier_info = {}  # Dictionary to store information about outliers\n",
    "    \n",
    "    for column in df_cleaned.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = df_cleaned[column].quantile(0.25)\n",
    "        Q3 = df_cleaned[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Identify outliers\n",
    "        outliers = df_cleaned[(df_cleaned[column] < lower_bound) | (df_cleaned[column] > upper_bound)]\n",
    "        \n",
    "        # Store the count of outliers\n",
    "        outlier_info[column] = outliers.shape[0]\n",
    "        \n",
    "        # Replace outliers with median of the column\n",
    "        median_value = df_cleaned[column].median()\n",
    "        df_cleaned.loc[(df_cleaned[column] < lower_bound) | (df_cleaned[column] > upper_bound), column] = median_value\n",
    "    \n",
    "    return df_cleaned, outlier_info\n",
    "\n",
    "# Apply the function to handle outliers\n",
    "df_cleaned, outlier_info = handle_outliers_iqr(df)\n",
    "\n",
    "# Display the number of rows after outlier removal\n",
    "print(f\"Number of rows after outlier removal: {df_cleaned.shape[0]}\")\n",
    "\n",
    "# Display information about outliers\n",
    "total_outliers_removed = sum(outlier_info.values())\n",
    "print(f\"\\nTotal number of outliers removed: {total_outliers_removed}\")\n",
    "\n",
    "# Store the cleaned DataFrame in a new DataFrame\n",
    "df_outliers_removed = df_cleaned.copy()\n",
    "\n",
    "# Optionally, display the cleaned DataFrame's first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame with outliers removed:\")\n",
    "print(df_outliers_removed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before outlier removal: 150001\n",
      "Number of rows after outlier removal: 150001\n",
      "\n",
      "Total number of outliers removed: 451082\n",
      "\n",
      "First few rows of the DataFrame with outliers removed:\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0    86399.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1    86399.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2    86399.0  2.082015e+14   3.366371e+10  3.528151e+13   \n",
      "3    86399.0  2.082014e+14   3.366371e+10  3.535661e+13   \n",
      "4    86399.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Display the number of rows before outlier removal\n",
    "print(f\"Number of rows before outlier removal: {df.shape[0]}\")\n",
    "\n",
    "# Function to identify and replace outliers using IQR method\n",
    "def handle_outliers_iqr(df):\n",
    "    df_cleaned = df.copy()  # Create a copy of the DataFrame for modifications\n",
    "    outlier_info = {}  # Dictionary to store information about outliers\n",
    "    \n",
    "    for column in df_cleaned.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = df_cleaned[column].quantile(0.25)\n",
    "        Q3 = df_cleaned[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Identify outliers\n",
    "        outliers = df_cleaned[(df_cleaned[column] < lower_bound) | (df_cleaned[column] > upper_bound)]\n",
    "        \n",
    "        # Store the count of outliers\n",
    "        outlier_info[column] = outliers.shape[0]\n",
    "        \n",
    "        # Replace outliers with median of the column\n",
    "        median_value = df_cleaned[column].median()\n",
    "        df_cleaned.loc[(df_cleaned[column] < lower_bound) | (df_cleaned[column] > upper_bound), column] = median_value\n",
    "    \n",
    "    return df_cleaned, outlier_info\n",
    "\n",
    "# Apply the function to handle outliers\n",
    "df_cleaned, outlier_info = handle_outliers_iqr(df)\n",
    "\n",
    "# Display the number of rows after outlier removal\n",
    "print(f\"Number of rows after outlier removal: {df_cleaned.shape[0]}\")\n",
    "\n",
    "# Display information about outliers\n",
    "total_outliers_removed = sum(outlier_info.values())\n",
    "print(f\"\\nTotal number of outliers removed: {total_outliers_removed}\")\n",
    "\n",
    "# Store the cleaned DataFrame in a new DataFrame\n",
    "df_outliers_removed = df_cleaned.copy()\n",
    "\n",
    "# Optionally, display the cleaned DataFrame's first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame with outliers removed:\")\n",
    "print(df_outliers_removed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Bearer Id                                   0\n",
      "Start                                       0\n",
      "Start ms                                    0\n",
      "End                                         0\n",
      "End ms                                      0\n",
      "Dur. (ms)                                   0\n",
      "IMSI                                        0\n",
      "MSISDN/Number                               0\n",
      "IMEI                                        0\n",
      "Last Location Name                          0\n",
      "Avg RTT DL (ms)                             0\n",
      "Avg RTT UL (ms)                             0\n",
      "Avg Bearer TP DL (kbps)                     0\n",
      "Avg Bearer TP UL (kbps)                     0\n",
      "TCP DL Retrans. Vol (Bytes)                 0\n",
      "TCP UL Retrans. Vol (Bytes)                 0\n",
      "DL TP < 50 Kbps (%)                         0\n",
      "50 Kbps < DL TP < 250 Kbps (%)              0\n",
      "250 Kbps < DL TP < 1 Mbps (%)               0\n",
      "DL TP > 1 Mbps (%)                          0\n",
      "UL TP < 10 Kbps (%)                         0\n",
      "10 Kbps < UL TP < 50 Kbps (%)               0\n",
      "50 Kbps < UL TP < 300 Kbps (%)              0\n",
      "UL TP > 300 Kbps (%)                        0\n",
      "HTTP DL (Bytes)                             0\n",
      "HTTP UL (Bytes)                             0\n",
      "Activity Duration DL (ms)                   0\n",
      "Activity Duration UL (ms)                   0\n",
      "Dur. (ms).1                                 0\n",
      "Handset Manufacturer                        0\n",
      "Handset Type                                0\n",
      "Nb of sec with 125000B < Vol DL             0\n",
      "Nb of sec with 1250B < Vol UL < 6250B       0\n",
      "Nb of sec with 31250B < Vol DL < 125000B    0\n",
      "Nb of sec with 37500B < Vol UL              0\n",
      "Nb of sec with 6250B < Vol DL < 31250B      0\n",
      "Nb of sec with 6250B < Vol UL < 37500B      0\n",
      "Nb of sec with Vol DL < 6250B               0\n",
      "Nb of sec with Vol UL < 1250B               0\n",
      "Social Media DL (Bytes)                     0\n",
      "Social Media UL (Bytes)                     0\n",
      "Google DL (Bytes)                           0\n",
      "Google UL (Bytes)                           0\n",
      "Email DL (Bytes)                            0\n",
      "Email UL (Bytes)                            0\n",
      "Youtube DL (Bytes)                          0\n",
      "Youtube UL (Bytes)                          0\n",
      "Netflix DL (Bytes)                          0\n",
      "Netflix UL (Bytes)                          0\n",
      "Gaming DL (Bytes)                           0\n",
      "Gaming UL (Bytes)                           0\n",
      "Other DL (Bytes)                            0\n",
      "Other UL (Bytes)                            0\n",
      "Total UL (Bytes)                            0\n",
      "Total DL (Bytes)                            0\n",
      "dtype: int64\n",
      "\n",
      "First few rows of the DataFrame with missing values handled:\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0    86399.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1    86399.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2    86399.0  2.082015e+14   3.366371e+10  3.528151e+13   \n",
      "3    86399.0  2.082014e+14   3.366371e+10  3.535661e+13   \n",
      "4    86399.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to handle missing values using advanced statistical methods\n",
    "def handle_missing_values(df):\n",
    "    df_filled = df.copy()  # Create a copy of the DataFrame for modifications\n",
    "    \n",
    "    for column in df_filled.columns:\n",
    "        # If the column is numeric (float or int), replace missing values with the median\n",
    "        if df_filled[column].dtype in ['float64', 'int64']:\n",
    "            median_value = df_filled[column].median()\n",
    "            df_filled[column] = df_filled[column].fillna(median_value)\n",
    "        # If the column is categorical (object), replace missing values with the mode (most frequent value)\n",
    "        elif df_filled[column].dtype == 'object':\n",
    "            mode_value = df_filled[column].mode()[0]\n",
    "            df_filled[column] = df_filled[column].fillna(mode_value)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "# Apply the function to handle missing values\n",
    "df_filled = handle_missing_values(df_outliers_removed)\n",
    "\n",
    "# Display information about missing values after handling\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df_filled.isnull().sum())\n",
    "\n",
    "# Store the results in a new DataFrame\n",
    "df_missing_values_handled = df_filled.copy()\n",
    "\n",
    "# Optionally, display the first few rows of the new DataFrame\n",
    "print(\"\\nFirst few rows of the DataFrame with missing values handled:\")\n",
    "print(df_missing_values_handled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame info after ensuring consistency:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150001 entries, 0 to 150000\n",
      "Data columns (total 55 columns):\n",
      " #   Column                                    Non-Null Count   Dtype  \n",
      "---  ------                                    --------------   -----  \n",
      " 0   Bearer Id                                 150001 non-null  float64\n",
      " 1   Start                                     150001 non-null  object \n",
      " 2   Start ms                                  150001 non-null  float64\n",
      " 3   End                                       150001 non-null  object \n",
      " 4   End ms                                    150001 non-null  float64\n",
      " 5   Dur. (ms)                                 150001 non-null  float64\n",
      " 6   IMSI                                      150001 non-null  float64\n",
      " 7   MSISDN/Number                             150001 non-null  float64\n",
      " 8   IMEI                                      150001 non-null  float64\n",
      " 9   Last Location Name                        150001 non-null  object \n",
      " 10  Avg RTT DL (ms)                           150001 non-null  float64\n",
      " 11  Avg RTT UL (ms)                           150001 non-null  float64\n",
      " 12  Avg Bearer TP DL (kbps)                   150001 non-null  float64\n",
      " 13  Avg Bearer TP UL (kbps)                   150001 non-null  float64\n",
      " 14  TCP DL Retrans. Vol (Bytes)               150001 non-null  float64\n",
      " 15  TCP UL Retrans. Vol (Bytes)               150001 non-null  float64\n",
      " 16  DL TP < 50 Kbps (%)                       150001 non-null  float64\n",
      " 17  50 Kbps < DL TP < 250 Kbps (%)            150001 non-null  float64\n",
      " 18  250 Kbps < DL TP < 1 Mbps (%)             150001 non-null  float64\n",
      " 19  DL TP > 1 Mbps (%)                        150001 non-null  float64\n",
      " 20  UL TP < 10 Kbps (%)                       150001 non-null  float64\n",
      " 21  10 Kbps < UL TP < 50 Kbps (%)             150001 non-null  float64\n",
      " 22  50 Kbps < UL TP < 300 Kbps (%)            150001 non-null  float64\n",
      " 23  UL TP > 300 Kbps (%)                      150001 non-null  float64\n",
      " 24  HTTP DL (Bytes)                           150001 non-null  float64\n",
      " 25  HTTP UL (Bytes)                           150001 non-null  float64\n",
      " 26  Activity Duration DL (ms)                 150001 non-null  float64\n",
      " 27  Activity Duration UL (ms)                 150001 non-null  float64\n",
      " 28  Dur. (ms).1                               150001 non-null  float64\n",
      " 29  Handset Manufacturer                      150001 non-null  object \n",
      " 30  Handset Type                              150001 non-null  object \n",
      " 31  Nb of sec with 125000B < Vol DL           150001 non-null  float64\n",
      " 32  Nb of sec with 1250B < Vol UL < 6250B     150001 non-null  float64\n",
      " 33  Nb of sec with 31250B < Vol DL < 125000B  150001 non-null  float64\n",
      " 34  Nb of sec with 37500B < Vol UL            150001 non-null  float64\n",
      " 35  Nb of sec with 6250B < Vol DL < 31250B    150001 non-null  float64\n",
      " 36  Nb of sec with 6250B < Vol UL < 37500B    150001 non-null  float64\n",
      " 37  Nb of sec with Vol DL < 6250B             150001 non-null  float64\n",
      " 38  Nb of sec with Vol UL < 1250B             150001 non-null  float64\n",
      " 39  Social Media DL (Bytes)                   150001 non-null  float64\n",
      " 40  Social Media UL (Bytes)                   150001 non-null  float64\n",
      " 41  Google DL (Bytes)                         150001 non-null  float64\n",
      " 42  Google UL (Bytes)                         150001 non-null  float64\n",
      " 43  Email DL (Bytes)                          150001 non-null  float64\n",
      " 44  Email UL (Bytes)                          150001 non-null  float64\n",
      " 45  Youtube DL (Bytes)                        150001 non-null  float64\n",
      " 46  Youtube UL (Bytes)                        150001 non-null  float64\n",
      " 47  Netflix DL (Bytes)                        150001 non-null  float64\n",
      " 48  Netflix UL (Bytes)                        150001 non-null  float64\n",
      " 49  Gaming DL (Bytes)                         150001 non-null  float64\n",
      " 50  Gaming UL (Bytes)                         150001 non-null  float64\n",
      " 51  Other DL (Bytes)                          150001 non-null  float64\n",
      " 52  Other UL (Bytes)                          150001 non-null  float64\n",
      " 53  Total UL (Bytes)                          150001 non-null  float64\n",
      " 54  Total DL (Bytes)                          150001 non-null  float64\n",
      "dtypes: float64(50), object(5)\n",
      "memory usage: 62.9+ MB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame after ensuring consistency:\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0    86399.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1    86399.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2    86399.0  2.082015e+14   3.366371e+10  3.528151e+13   \n",
      "3    86399.0  2.082014e+14   3.366371e+10  3.535661e+13   \n",
      "4    86399.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure consistency in the dataset\n",
    "def ensure_consistency(df):\n",
    "    # Remove duplicate entries\n",
    "    df_cleaned = df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Convert data types to appropriate types\n",
    "    for column in df_cleaned.columns:\n",
    "        # If the column contains numeric data but is stored as an object, convert it to numeric\n",
    "        if df_cleaned[column].dtype == 'object':\n",
    "            try:\n",
    "                df_cleaned[column] = pd.to_numeric(df_cleaned[column])\n",
    "            except ValueError:\n",
    "                # If conversion fails, it's likely a categorical column, so leave it as is\n",
    "                pass\n",
    "        \n",
    "        # Convert datetime-like strings to actual datetime objects with a specific format if possible\n",
    "        if df_cleaned[column].dtype == 'object':\n",
    "            sample_value = df_cleaned[column].dropna().iloc[0]  # Take a sample value from the column\n",
    "            try:\n",
    "                # Check if the sample value looks like a date and if so, convert the entire column\n",
    "                if isinstance(pd.to_datetime(sample_value, format='%Y-%m-%d', errors='raise'), pd.Timestamp):\n",
    "                    df_cleaned[column] = pd.to_datetime(df_cleaned[column], format='%Y-%m-%d', errors='coerce')\n",
    "                elif isinstance(pd.to_datetime(sample_value, format='%d/%m/%Y', errors='raise'), pd.Timestamp):\n",
    "                    df_cleaned[column] = pd.to_datetime(df_cleaned[column], format='%d/%m/%Y', errors='coerce')\n",
    "                # Add other date formats as needed\n",
    "            except (ValueError, TypeError):\n",
    "                # If conversion fails, leave the column as is\n",
    "                pass\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply the function to the df_missing_values_handled DataFrame\n",
    "df_cleaned = ensure_consistency(df_missing_values_handled)\n",
    "\n",
    "# Optionally, display information about the cleaned DataFrame\n",
    "print(\"DataFrame info after ensuring consistency:\")\n",
    "print(df_cleaned.info())\n",
    "\n",
    "# Optionally, display the first few rows of the cleaned DataFrame\n",
    "print(\"\\nFirst few rows of the DataFrame after ensuring consistency:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame info after ensuring consistency:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150001 entries, 0 to 150000\n",
      "Data columns (total 55 columns):\n",
      " #   Column                                    Non-Null Count   Dtype  \n",
      "---  ------                                    --------------   -----  \n",
      " 0   Bearer Id                                 150001 non-null  float64\n",
      " 1   Start                                     150001 non-null  object \n",
      " 2   Start ms                                  150001 non-null  float64\n",
      " 3   End                                       150001 non-null  object \n",
      " 4   End ms                                    150001 non-null  float64\n",
      " 5   Dur. (ms)                                 150001 non-null  float64\n",
      " 6   IMSI                                      150001 non-null  float64\n",
      " 7   MSISDN/Number                             150001 non-null  float64\n",
      " 8   IMEI                                      150001 non-null  float64\n",
      " 9   Last Location Name                        150001 non-null  object \n",
      " 10  Avg RTT DL (ms)                           150001 non-null  float64\n",
      " 11  Avg RTT UL (ms)                           150001 non-null  float64\n",
      " 12  Avg Bearer TP DL (kbps)                   150001 non-null  float64\n",
      " 13  Avg Bearer TP UL (kbps)                   150001 non-null  float64\n",
      " 14  TCP DL Retrans. Vol (Bytes)               150001 non-null  float64\n",
      " 15  TCP UL Retrans. Vol (Bytes)               150001 non-null  float64\n",
      " 16  DL TP < 50 Kbps (%)                       150001 non-null  float64\n",
      " 17  50 Kbps < DL TP < 250 Kbps (%)            150001 non-null  float64\n",
      " 18  250 Kbps < DL TP < 1 Mbps (%)             150001 non-null  float64\n",
      " 19  DL TP > 1 Mbps (%)                        150001 non-null  float64\n",
      " 20  UL TP < 10 Kbps (%)                       150001 non-null  float64\n",
      " 21  10 Kbps < UL TP < 50 Kbps (%)             150001 non-null  float64\n",
      " 22  50 Kbps < UL TP < 300 Kbps (%)            150001 non-null  float64\n",
      " 23  UL TP > 300 Kbps (%)                      150001 non-null  float64\n",
      " 24  HTTP DL (Bytes)                           150001 non-null  float64\n",
      " 25  HTTP UL (Bytes)                           150001 non-null  float64\n",
      " 26  Activity Duration DL (ms)                 150001 non-null  float64\n",
      " 27  Activity Duration UL (ms)                 150001 non-null  float64\n",
      " 28  Dur. (ms).1                               150001 non-null  float64\n",
      " 29  Handset Manufacturer                      150001 non-null  object \n",
      " 30  Handset Type                              150001 non-null  object \n",
      " 31  Nb of sec with 125000B < Vol DL           150001 non-null  float64\n",
      " 32  Nb of sec with 1250B < Vol UL < 6250B     150001 non-null  float64\n",
      " 33  Nb of sec with 31250B < Vol DL < 125000B  150001 non-null  float64\n",
      " 34  Nb of sec with 37500B < Vol UL            150001 non-null  float64\n",
      " 35  Nb of sec with 6250B < Vol DL < 31250B    150001 non-null  float64\n",
      " 36  Nb of sec with 6250B < Vol UL < 37500B    150001 non-null  float64\n",
      " 37  Nb of sec with Vol DL < 6250B             150001 non-null  float64\n",
      " 38  Nb of sec with Vol UL < 1250B             150001 non-null  float64\n",
      " 39  Social Media DL (Bytes)                   150001 non-null  float64\n",
      " 40  Social Media UL (Bytes)                   150001 non-null  float64\n",
      " 41  Google DL (Bytes)                         150001 non-null  float64\n",
      " 42  Google UL (Bytes)                         150001 non-null  float64\n",
      " 43  Email DL (Bytes)                          150001 non-null  float64\n",
      " 44  Email UL (Bytes)                          150001 non-null  float64\n",
      " 45  Youtube DL (Bytes)                        150001 non-null  float64\n",
      " 46  Youtube UL (Bytes)                        150001 non-null  float64\n",
      " 47  Netflix DL (Bytes)                        150001 non-null  float64\n",
      " 48  Netflix UL (Bytes)                        150001 non-null  float64\n",
      " 49  Gaming DL (Bytes)                         150001 non-null  float64\n",
      " 50  Gaming UL (Bytes)                         150001 non-null  float64\n",
      " 51  Other DL (Bytes)                          150001 non-null  float64\n",
      " 52  Other UL (Bytes)                          150001 non-null  float64\n",
      " 53  Total UL (Bytes)                          150001 non-null  float64\n",
      " 54  Total DL (Bytes)                          150001 non-null  float64\n",
      "dtypes: float64(50), object(5)\n",
      "memory usage: 62.9+ MB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame after ensuring consistency:\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0    86399.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1    86399.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2    86399.0  2.082015e+14   3.366371e+10  3.528151e+13   \n",
      "3    86399.0  2.082014e+14   3.366371e+10  3.535661e+13   \n",
      "4    86399.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure consistency in the dataset\n",
    "def ensure_consistency(df):\n",
    "    # Remove duplicate entries\n",
    "    df_cleaned = df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Convert data types to appropriate types\n",
    "    for column in df_cleaned.columns:\n",
    "        # If the column contains numeric data but is stored as an object, convert it to numeric\n",
    "        if df_cleaned[column].dtype == 'object':\n",
    "            try:\n",
    "                df_cleaned[column] = pd.to_numeric(df_cleaned[column])\n",
    "            except ValueError:\n",
    "                # If conversion fails, it's likely a categorical column, so leave it as is\n",
    "                pass\n",
    "        \n",
    "        # Convert datetime-like strings to actual datetime objects with a specific format if possible\n",
    "        if df_cleaned[column].dtype == 'object':\n",
    "            sample_value = df_cleaned[column].dropna().iloc[0]  # Take a sample value from the column\n",
    "            try:\n",
    "                # Check if the sample value looks like a date and if so, convert the entire column\n",
    "                if isinstance(pd.to_datetime(sample_value, format='%Y-%m-%d', errors='raise'), pd.Timestamp):\n",
    "                    df_cleaned[column] = pd.to_datetime(df_cleaned[column], format='%Y-%m-%d', errors='coerce')\n",
    "                elif isinstance(pd.to_datetime(sample_value, format='%d/%m/%Y', errors='raise'), pd.Timestamp):\n",
    "                    df_cleaned[column] = pd.to_datetime(df_cleaned[column], format='%d/%m/%Y', errors='coerce')\n",
    "                # Add other date formats as needed\n",
    "            except (ValueError, TypeError):\n",
    "                # If conversion fails, leave the column as is\n",
    "                pass\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply the function to the df_missing_values_handled DataFrame\n",
    "df_cleaned = ensure_consistency(df_missing_values_handled)\n",
    "\n",
    "# Optionally, display information about the cleaned DataFrame\n",
    "print(\"DataFrame info after ensuring consistency:\")\n",
    "print(df_cleaned.info())\n",
    "\n",
    "# Optionally, display the first few rows of the cleaned DataFrame\n",
    "print(\"\\nFirst few rows of the DataFrame after ensuring consistency:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting done with the cleaning of the data we proceed with calculating metrics like average TCP retransmission, average RTT, handset type, and average throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bearer Id', 'Start', 'Start ms', 'End', 'End ms', 'Dur. (ms)', 'IMSI', 'MSISDN/Number', 'IMEI', 'Last Location Name', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)', 'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', 'DL TP < 50 Kbps (%)', '50 Kbps < DL TP < 250 Kbps (%)', '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)', 'UL TP < 10 Kbps (%)', '10 Kbps < UL TP < 50 Kbps (%)', '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)', 'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Activity Duration DL (ms)', 'Activity Duration UL (ms)', 'Dur. (ms).1', 'Handset Manufacturer', 'Handset Type', 'Nb of sec with 125000B < Vol DL', 'Nb of sec with 1250B < Vol UL < 6250B', 'Nb of sec with 31250B < Vol DL < 125000B', 'Nb of sec with 37500B < Vol UL', 'Nb of sec with 6250B < Vol DL < 31250B', 'Nb of sec with 6250B < Vol UL < 37500B', 'Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B', 'Social Media DL (Bytes)', 'Social Media UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)', 'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)', 'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)', 'Total UL (Bytes)', 'Total DL (Bytes)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               IMSI  Avg_TCP_Retransmission  Avg_RTT  \\\n",
      "0      2.082009e+14              589676.750     23.0   \n",
      "1      2.082009e+14              324801.375     19.5   \n",
      "2      2.082009e+14              715257.000     45.0   \n",
      "3      2.082009e+14              589676.750     24.0   \n",
      "4      2.082009e+14              101833.000     45.0   \n",
      "...             ...                     ...      ...   \n",
      "97420  2.082022e+14              581000.000    121.0   \n",
      "97421  2.082022e+14             1966143.750     38.0   \n",
      "97422  2.082022e+14              589676.750     45.0   \n",
      "97423  2.082022e+14              589676.750     45.0   \n",
      "97424  2.082022e+14              589676.750     46.0   \n",
      "\n",
      "                               Handset_Type  Avg_Throughput  \n",
      "0                    Apple iPhone 6 (A1549)           54.75  \n",
      "1                    Apple iPhone 6 (A1586)         7563.00  \n",
      "2                   Apple iPhone 6S (A1688)        15776.50  \n",
      "3                            Huawei Y6 2018           55.50  \n",
      "4      Samsung Galaxy S3 Mini Ve(Gt-I8200X)          849.00  \n",
      "...                                     ...             ...  \n",
      "97420               Apple iPhone 5S (A1457)          558.00  \n",
      "97421           Apple iPhone 8 Plus (A1897)          342.50  \n",
      "97422           Samsung Galaxy J3 (Sm-J330)            7.50  \n",
      "97423                      Samsung Sm-G390F            7.50  \n",
      "97424               Apple iPhone Xs (A2097)          214.50  \n",
      "\n",
      "[97425 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "# Convert 'Start' to a datetime object if it's not already\n",
    "df_cleaned['Start'] = pd.to_datetime(df_cleaned['Start'])\n",
    "\n",
    "# Define a function to compute the required metrics\n",
    "def aggregate_customer_info(df):\n",
    "    # Calculate average TCP retransmission (sum of DL and UL retransmission volumes divided by total duration)\n",
    "    df['Total_TCP_Retransmission'] = df['TCP DL Retrans. Vol (Bytes)'] + df['TCP UL Retrans. Vol (Bytes)']\n",
    "    df['Total_Duration'] = df['Dur. (ms)'] / 1000  # Convert duration to seconds\n",
    "    \n",
    "    # Calculate average throughput (DL and UL throughputs)\n",
    "    df['Avg_Throughput_DL'] = df['Avg Bearer TP DL (kbps)']\n",
    "    df['Avg_Throughput_UL'] = df['Avg Bearer TP UL (kbps)']\n",
    "    \n",
    "    # Group by customer (using IMSI as the customer identifier)\n",
    "    aggregated_df = df.groupby('IMSI').agg(\n",
    "        Avg_TCP_Retransmission=('Total_TCP_Retransmission', 'mean'),\n",
    "        Avg_RTT=('Avg RTT DL (ms)', 'mean'),\n",
    "        Handset_Type=('Handset Type', 'first'),  # Assuming the handset type is the same for each customer\n",
    "        Avg_Throughput_DL=('Avg_Throughput_DL', 'mean'),\n",
    "        Avg_Throughput_UL=('Avg_Throughput_UL', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Combine DL and UL throughput into a single average throughput column\n",
    "    aggregated_df['Avg_Throughput'] = (aggregated_df['Avg_Throughput_DL'] + aggregated_df['Avg_Throughput_UL']) / 2\n",
    "    \n",
    "    # Drop the separate throughput columns if needed\n",
    "    aggregated_df.drop(columns=['Avg_Throughput_DL', 'Avg_Throughput_UL'], inplace=True)\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Execute the aggregation\n",
    "result_df = aggregate_customer_info(df_cleaned)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase two  \n",
    "In this phase we are going to cinduct Exploratotry data analsyis by going through computing and listing the top, Bottom and most frequent:  \n",
    "a. TCP values\n",
    "b. RTT values\n",
    "c. Throughput values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TCP Metrics\n",
      "\n",
      "Metric: TCP Downlink Retransmission Volume (Bytes)\n",
      "Top 10 Values:\n",
      "0    9365124.0\n",
      "1    9364198.0\n",
      "2    9363921.0\n",
      "3    9360672.0\n",
      "4    9357734.0\n",
      "5    9356205.0\n",
      "6    9354511.0\n",
      "7    9353799.0\n",
      "8    9349630.0\n",
      "9    9349188.0\n",
      "Name: TCP DL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    2.0\n",
      "1    2.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    4.0\n",
      "5    4.0\n",
      "6    4.0\n",
      "7    4.0\n",
      "8    4.0\n",
      "9    4.0\n",
      "Name: TCP DL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    568730.0\n",
      "Name: TCP DL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "Metric: TCP Uplink Retransmission Volume (Bytes)\n",
      "Top 10 Values:\n",
      "0    203003.0\n",
      "1    202966.0\n",
      "2    202952.0\n",
      "3    202856.0\n",
      "4    202781.0\n",
      "5    202763.0\n",
      "6    202677.0\n",
      "7    202665.0\n",
      "8    202640.0\n",
      "9    202635.0\n",
      "Name: TCP UL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    1.0\n",
      "7    1.0\n",
      "8    1.0\n",
      "9    1.0\n",
      "Name: TCP UL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    20946.75\n",
      "Name: TCP UL Retrans. Vol (Bytes), dtype: float64\n",
      "\n",
      "RTT Metrics\n",
      "\n",
      "Metric: Average Downlink RTT (ms)\n",
      "Top 10 Values:\n",
      "0    127.0\n",
      "1    127.0\n",
      "2    127.0\n",
      "3    127.0\n",
      "4    127.0\n",
      "5    127.0\n",
      "6    127.0\n",
      "7    127.0\n",
      "8    127.0\n",
      "9    127.0\n",
      "Name: Avg RTT DL (ms), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    2.0\n",
      "Name: Avg RTT DL (ms), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    45.0\n",
      "Name: Avg RTT DL (ms), dtype: float64\n",
      "\n",
      "Metric: Average Uplink RTT (ms)\n",
      "Top 10 Values:\n",
      "0    34.0\n",
      "1    34.0\n",
      "2    34.0\n",
      "3    34.0\n",
      "4    34.0\n",
      "5    34.0\n",
      "6    34.0\n",
      "7    34.0\n",
      "8    34.0\n",
      "9    34.0\n",
      "Name: Avg RTT UL (ms), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Name: Avg RTT UL (ms), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    5.0\n",
      "Name: Avg RTT UL (ms), dtype: float64\n",
      "\n",
      "Throughput Metrics\n",
      "\n",
      "Metric: Average Downlink Throughput (kbps)\n",
      "Top 10 Values:\n",
      "0    49211.0\n",
      "1    49205.0\n",
      "2    49205.0\n",
      "3    49205.0\n",
      "4    49202.0\n",
      "5    49202.0\n",
      "6    49200.0\n",
      "7    49200.0\n",
      "8    49198.0\n",
      "9    49195.0\n",
      "Name: Avg Bearer TP DL (kbps), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Name: Avg Bearer TP DL (kbps), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    63.0\n",
      "Name: Avg Bearer TP DL (kbps), dtype: float64\n",
      "\n",
      "Metric: Average Uplink Throughput (kbps)\n",
      "Top 10 Values:\n",
      "0    2729.0\n",
      "1    2729.0\n",
      "2    2729.0\n",
      "3    2729.0\n",
      "4    2729.0\n",
      "5    2729.0\n",
      "6    2729.0\n",
      "7    2729.0\n",
      "8    2729.0\n",
      "9    2729.0\n",
      "Name: Avg Bearer TP UL (kbps), dtype: float64\n",
      "\n",
      "Bottom 10 Values:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Name: Avg Bearer TP UL (kbps), dtype: float64\n",
      "\n",
      "Most Frequent Values:\n",
      "0    63.0\n",
      "Name: Avg Bearer TP UL (kbps), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "\n",
    "# Define columns for analysis with descriptive names\n",
    "tcp_columns = {\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'TCP Downlink Retransmission Volume (Bytes)',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'TCP Uplink Retransmission Volume (Bytes)'\n",
    "}\n",
    "rtt_columns = {\n",
    "    'Avg RTT DL (ms)': 'Average Downlink RTT (ms)',\n",
    "    'Avg RTT UL (ms)': 'Average Uplink RTT (ms)'\n",
    "}\n",
    "throughput_columns = {\n",
    "    'Avg Bearer TP DL (kbps)': 'Average Downlink Throughput (kbps)',\n",
    "    'Avg Bearer TP UL (kbps)': 'Average Uplink Throughput (kbps)'\n",
    "}\n",
    "\n",
    "def compute_metrics(df, columns_dict):\n",
    "    metrics = {}\n",
    "    for col, desc in columns_dict.items():\n",
    "        # Top 10 values\n",
    "        top_10 = df[col].nlargest(10).reset_index(drop=True)\n",
    "        \n",
    "        # Bottom 10 values\n",
    "        bottom_10 = df[col].nsmallest(10).reset_index(drop=True)\n",
    "        \n",
    "        # Most frequent values\n",
    "        most_frequent = df[col].mode().head(10).reset_index(drop=True)\n",
    "        \n",
    "        metrics[desc] = {\n",
    "            'Top 10': top_10,\n",
    "            'Bottom 10': bottom_10,\n",
    "            'Most Frequent': most_frequent\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Compute metrics for TCP values\n",
    "tcp_metrics = compute_metrics(df_cleaned, tcp_columns)\n",
    "\n",
    "# Compute metrics for RTT values\n",
    "rtt_metrics = compute_metrics(df_cleaned, rtt_columns)\n",
    "\n",
    "# Compute metrics for Throughput values\n",
    "throughput_metrics = compute_metrics(df_cleaned, throughput_columns)\n",
    "\n",
    "# Print the results with descriptive names\n",
    "def print_metrics(metrics, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for desc, data in metrics.items():\n",
    "        print(f\"\\nMetric: {desc}\")\n",
    "        print(\"Top 10 Values:\")\n",
    "        print(data['Top 10'])\n",
    "        print(\"\\nBottom 10 Values:\")\n",
    "        print(data['Bottom 10'])\n",
    "        print(\"\\nMost Frequent Values:\")\n",
    "        print(data['Most Frequent'])\n",
    "\n",
    "print_metrics(tcp_metrics, \"TCP Metrics\")\n",
    "print_metrics(rtt_metrics, \"RTT Metrics\")\n",
    "print_metrics(throughput_metrics, \"Throughput Metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3 Feature analysis and interpretation  \n",
    "In this phase we are going to show the distribution of the average throughput per handset type and the average TCP retransmission per handset type. Also, we are going to interpret the results from this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Average Throughput per Handset Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Average Throughput per Handset Type:\n",
      "                                                     count          mean  \\\n",
      "Handset Type                                                               \n",
      "A-Link Telecom I. Cubot A5                             1.0  11755.000000   \n",
      "A-Link Telecom I. Cubot Note Plus                      1.0   3349.500000   \n",
      "A-Link Telecom I. Cubot Note S                         1.0   4468.500000   \n",
      "A-Link Telecom I. Cubot Nova                           1.0    306.500000   \n",
      "A-Link Telecom I. Cubot Power                          1.0    202.500000   \n",
      "...                                                    ...           ...   \n",
      "Zte Zte Blade C2 Smartphone Android By Sfr Star...     2.0     29.000000   \n",
      "Zyxel Communicat. Lte7460                              1.0  19902.000000   \n",
      "Zyxel Communicat. Sbg3600                              1.0     63.000000   \n",
      "Zyxel Communicat. Zyxel Wah7706                        1.0   1086.500000   \n",
      "undefined                                           8987.0   2240.864193   \n",
      "\n",
      "                                                            std      min  \\\n",
      "Handset Type                                                               \n",
      "A-Link Telecom I. Cubot A5                                  NaN  11755.0   \n",
      "A-Link Telecom I. Cubot Note Plus                           NaN   3349.5   \n",
      "A-Link Telecom I. Cubot Note S                              NaN   4468.5   \n",
      "A-Link Telecom I. Cubot Nova                                NaN    306.5   \n",
      "A-Link Telecom I. Cubot Power                               NaN    202.5   \n",
      "...                                                         ...      ...   \n",
      "Zte Zte Blade C2 Smartphone Android By Sfr Star...    36.769553      3.0   \n",
      "Zyxel Communicat. Lte7460                                   NaN  19902.0   \n",
      "Zyxel Communicat. Sbg3600                                   NaN     63.0   \n",
      "Zyxel Communicat. Zyxel Wah7706                             NaN   1086.5   \n",
      "undefined                                           5251.859698      0.0   \n",
      "\n",
      "                                                        25%      50%  \\\n",
      "Handset Type                                                           \n",
      "A-Link Telecom I. Cubot A5                          11755.0  11755.0   \n",
      "A-Link Telecom I. Cubot Note Plus                    3349.5   3349.5   \n",
      "A-Link Telecom I. Cubot Note S                       4468.5   4468.5   \n",
      "A-Link Telecom I. Cubot Nova                          306.5    306.5   \n",
      "A-Link Telecom I. Cubot Power                         202.5    202.5   \n",
      "...                                                     ...      ...   \n",
      "Zte Zte Blade C2 Smartphone Android By Sfr Star...     16.0     29.0   \n",
      "Zyxel Communicat. Lte7460                           19902.0  19902.0   \n",
      "Zyxel Communicat. Sbg3600                              63.0     63.0   \n",
      "Zyxel Communicat. Zyxel Wah7706                      1086.5   1086.5   \n",
      "undefined                                              37.0     52.0   \n",
      "\n",
      "                                                         75%      max  \n",
      "Handset Type                                                           \n",
      "A-Link Telecom I. Cubot A5                          11755.00  11755.0  \n",
      "A-Link Telecom I. Cubot Note Plus                    3349.50   3349.5  \n",
      "A-Link Telecom I. Cubot Note S                       4468.50   4468.5  \n",
      "A-Link Telecom I. Cubot Nova                          306.50    306.5  \n",
      "A-Link Telecom I. Cubot Power                         202.50    202.5  \n",
      "...                                                      ...      ...  \n",
      "Zte Zte Blade C2 Smartphone Android By Sfr Star...     42.00     55.0  \n",
      "Zyxel Communicat. Lte7460                           19902.00  19902.0  \n",
      "Zyxel Communicat. Sbg3600                              63.00     63.0  \n",
      "Zyxel Communicat. Zyxel Wah7706                      1086.50   1086.5  \n",
      "undefined                                             532.75  25847.5  \n",
      "\n",
      "[1396 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "\n",
    "# Define columns for throughput\n",
    "throughput_columns = ['Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)']\n",
    "\n",
    "# Compute average throughput per handset type\n",
    "def compute_avg_throughput_per_handset(df, throughput_cols):\n",
    "    # Calculate average throughput for DL and UL\n",
    "    df['Avg_Throughput_DL'] = df[throughput_cols[0]]\n",
    "    df['Avg_Throughput_UL'] = df[throughput_cols[1]]\n",
    "    \n",
    "    # Combine DL and UL throughput into a single average throughput\n",
    "    df['Avg_Throughput'] = (df['Avg_Throughput_DL'] + df['Avg_Throughput_UL']) / 2\n",
    "    \n",
    "    # Group by handset type and calculate the distribution of average throughput\n",
    "    distribution = df.groupby('Handset Type')['Avg_Throughput'].describe()\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "# Execute the computation\n",
    "throughput_distribution = compute_avg_throughput_per_handset(df_cleaned, throughput_columns)\n",
    "\n",
    "# Print the result\n",
    "print(\"Distribution of Average Throughput per Handset Type:\")\n",
    "print(throughput_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation for the above result on the distribution ofaverage throughput per handset type:  \n",
    "The distribution of average throughput per handset type reveals a wide variation in network performance across different devices. Some handsets, like the \"A-Link Telecom I. Cubot A5,\" experience exceptionally high average throughput (over 11,000 kbps), while others, such as the \"Zte Zte Blade C2,\" show much lower performance (around 29 kbps). This variation suggests that certain handset models are better optimized for higher data speeds, possibly due to differences in hardware capabilities, network compatibility, or even user location and usage patterns.\n",
    "\n",
    "Interestingly, a large group of devices is classified under \"undefined,\" showing a significant spread in average throughput, with a maximum value of over 25,000 kbps but also a median of only 52 kbps. This category may represent unclassified or generic handsets, indicating that further refinement in data classification could be beneficial to gain a clearer understanding of performance distribution across known models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TCP re-transmission view per handset type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TCP Retransmission per Handset Type:\n",
      "Handset Type\n",
      "A-Link Telecom I. Cubot A5                                                             294838.375000\n",
      "A-Link Telecom I. Cubot Note Plus                                                      308106.500000\n",
      "A-Link Telecom I. Cubot Note S                                                         317991.000000\n",
      "A-Link Telecom I. Cubot Nova                                                            68585.000000\n",
      "A-Link Telecom I. Cubot Power                                                            4020.500000\n",
      "                                                                                           ...      \n",
      "Zte Zte Blade C2 Smartphone Android By Sfr Startrail 4 Zte Blade Flex T809 Zte T809    153320.875000\n",
      "Zyxel Communicat. Lte7460                                                              294839.750000\n",
      "Zyxel Communicat. Sbg3600                                                              294839.750000\n",
      "Zyxel Communicat. Zyxel Wah7706                                                         10531.375000\n",
      "undefined                                                                              333436.272727\n",
      "Name: Avg_TCP_Retransmission, Length: 1396, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "\n",
    "# Define columns for TCP retransmission\n",
    "tcp_columns = ['TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)']\n",
    "\n",
    "# Compute average TCP retransmission per handset type\n",
    "def compute_avg_tcp_retransmission_per_handset(df, tcp_cols):\n",
    "    # Calculate average TCP retransmission for DL and UL\n",
    "    df['Avg_TCP_Retransmission_DL'] = df[tcp_cols[0]]\n",
    "    df['Avg_TCP_Retransmission_UL'] = df[tcp_cols[1]]\n",
    "    \n",
    "    # Combine DL and UL TCP retransmission into a single average value\n",
    "    df['Avg_TCP_Retransmission'] = (df['Avg_TCP_Retransmission_DL'] + df['Avg_TCP_Retransmission_UL']) / 2\n",
    "    \n",
    "    # Group by handset type and calculate the average TCP retransmission\n",
    "    avg_retransmission = df.groupby('Handset Type')['Avg_TCP_Retransmission'].mean()\n",
    "    \n",
    "    return avg_retransmission\n",
    "\n",
    "# Execute the computation\n",
    "tcp_retransmission_avg = compute_avg_tcp_retransmission_per_handset(df_cleaned, tcp_columns)\n",
    "\n",
    "# Print the result\n",
    "print(\"Average TCP Retransmission per Handset Type:\")\n",
    "print(tcp_retransmission_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation for the above results on Average TCP re-transmission per handset type:  \n",
    "The average TCP retransmission values across different handset types highlight notable disparities in network performance. Devices like the \"A-Link Telecom I. Cubot Note Plus\" and \"A-Link Telecom I. Cubot Note S\" experience higher retransmissions, with averages exceeding 300,000 bytes. This suggests that these handsets might be struggling with maintaining stable network connections, leading to frequent retransmissions of data packets, which can negatively impact the user experience, particularly during activities like streaming or downloading.\n",
    "\n",
    "On the other end of the spectrum, devices like the \"A-Link Telecom I. Cubot Power\" and \"Zyxel Communicat. Zyxel Wah7706\" have much lower retransmission averages, indicating potentially more efficient communication with the network and better handling of data traffic. The \"undefined\" category shows a higher average retransmission of over 333,000 bytes, further suggesting that unclassified or less common handsets may be experiencing performance issues. This distribution underscores the importance of device optimization for reliable network performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage we are going to perform a k-means clustering(where k=3) Using the experience metrics above to segment groups into groups of experiences and provide a brief description of each cluster created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "\n",
    "# Select relevant experience metrics with descriptive names\n",
    "experience_metrics_descriptive = {\n",
    "    'Avg RTT DL (ms)': 'Average Downlink Round-Trip Time (ms)',\n",
    "    'Avg RTT UL (ms)': 'Average Uplink Round-Trip Time (ms)', \n",
    "    'Avg Bearer TP DL (kbps)': 'Average Downlink Throughput (kbps)',\n",
    "    'Avg Bearer TP UL (kbps)': 'Average Uplink Throughput (kbps)',\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'Downlink TCP Retransmission Volume (Bytes)',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'Uplink TCP Retransmission Volume (Bytes)'\n",
    "}\n",
    "\n",
    "# Drop rows with missing values in the selected columns\n",
    "df_experience = df_cleaned[list(experience_metrics_descriptive.keys())].dropna()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "experience_metrics_scaled = scaler.fit_transform(df_experience)\n",
    "\n",
    "# Convert scaled data back to a DataFrame for reference\n",
    "df_experience_scaled = pd.DataFrame(experience_metrics_scaled, columns=experience_metrics_descriptive.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-means clustering with k=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_experience_scaled['Experience Group'] = kmeans.fit_predict(experience_metrics_scaled)\n",
    "\n",
    "# Add the cluster labels to the original DataFrame with more descriptive names\n",
    "cluster_names = {\n",
    "    0: \"High-Performance Users\",\n",
    "    1: \"Moderate-Performance Users\",\n",
    "    2: \"Low-Performance Users\"\n",
    "}\n",
    "\n",
    "df_experience_scaled['Experience Group Name'] = df_experience_scaled['Experience Group'].map(cluster_names)\n",
    "df_cleaned['Experience Group Name'] = df_experience_scaled['Experience Group Name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Descriptions (Averages of Experience Metrics):\n",
      "                            Average Downlink Round-Trip Time (ms)  \\\n",
      "Experience Group Name                                               \n",
      "High-Performance Users                                  41.578110   \n",
      "Low-Performance Users                                   57.281174   \n",
      "Moderate-Performance Users                              64.838950   \n",
      "\n",
      "                            Average Uplink Round-Trip Time (ms)  \\\n",
      "Experience Group Name                                             \n",
      "High-Performance Users                                 4.730363   \n",
      "Low-Performance Users                                 13.134860   \n",
      "Moderate-Performance Users                            13.351035   \n",
      "\n",
      "                            Average Downlink Throughput (kbps)  \\\n",
      "Experience Group Name                                            \n",
      "High-Performance Users                             1046.690679   \n",
      "Low-Performance Users                             22036.653552   \n",
      "Moderate-Performance Users                        18977.601663   \n",
      "\n",
      "                            Average Uplink Throughput (kbps)  \\\n",
      "Experience Group Name                                          \n",
      "High-Performance Users                            104.889182   \n",
      "Low-Performance Users                             965.117552   \n",
      "Moderate-Performance Users                        620.447024   \n",
      "\n",
      "                            Downlink TCP Retransmission Volume (Bytes)  \\\n",
      "Experience Group Name                                                    \n",
      "High-Performance Users                                    5.383542e+05   \n",
      "Low-Performance Users                                     6.887798e+05   \n",
      "Moderate-Performance Users                                3.930157e+06   \n",
      "\n",
      "                            Uplink TCP Retransmission Volume (Bytes)  \n",
      "Experience Group Name                                                 \n",
      "High-Performance Users                                  20255.823332  \n",
      "Low-Performance Users                                   19446.066409  \n",
      "Moderate-Performance Users                              82261.171706  \n",
      "\n",
      "High-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 41.58 ms\n",
      "- Average Uplink Round-Trip Time: 4.73 ms\n",
      "- Average Downlink Throughput: 1046.69 kbps\n",
      "- Average Uplink Throughput: 104.89 kbps\n",
      "- Downlink TCP Retransmission Volume: 538354.19 Bytes\n",
      "- Uplink TCP Retransmission Volume: 20255.82 Bytes\n",
      "\n",
      "Low-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 57.28 ms\n",
      "- Average Uplink Round-Trip Time: 13.13 ms\n",
      "- Average Downlink Throughput: 22036.65 kbps\n",
      "- Average Uplink Throughput: 965.12 kbps\n",
      "- Downlink TCP Retransmission Volume: 688779.82 Bytes\n",
      "- Uplink TCP Retransmission Volume: 19446.07 Bytes\n",
      "\n",
      "Moderate-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 64.84 ms\n",
      "- Average Uplink Round-Trip Time: 13.35 ms\n",
      "- Average Downlink Throughput: 18977.60 kbps\n",
      "- Average Uplink Throughput: 620.45 kbps\n",
      "- Downlink TCP Retransmission Volume: 3930156.80 Bytes\n",
      "- Uplink TCP Retransmission Volume: 82261.17 Bytes\n"
     ]
    }
   ],
   "source": [
    "# Brief description of each cluster based on the average of experience metrics\n",
    "cluster_description = df_cleaned.groupby('Experience Group Name')[list(experience_metrics_descriptive.keys())].mean()\n",
    "cluster_description.columns = experience_metrics_descriptive.values()  # Update column names to descriptive\n",
    "\n",
    "# Print the cluster descriptions\n",
    "print(\"Cluster Descriptions (Averages of Experience Metrics):\")\n",
    "print(cluster_description)\n",
    "\n",
    "# Provide a brief interpretation of the clusters with descriptive labels\n",
    "for group_name in cluster_description.index:\n",
    "    print(f\"\\n{group_name}:\")\n",
    "    print(\"This group of users tends to have the following network experience characteristics:\")\n",
    "    print(f\"- Average Downlink Round-Trip Time: {cluster_description.loc[group_name, 'Average Downlink Round-Trip Time (ms)']:.2f} ms\")\n",
    "    print(f\"- Average Uplink Round-Trip Time: {cluster_description.loc[group_name, 'Average Uplink Round-Trip Time (ms)']:.2f} ms\")\n",
    "    print(f\"- Average Downlink Throughput: {cluster_description.loc[group_name, 'Average Downlink Throughput (kbps)']:.2f} kbps\")\n",
    "    print(f\"- Average Uplink Throughput: {cluster_description.loc[group_name, 'Average Uplink Throughput (kbps)']:.2f} kbps\")\n",
    "    print(f\"- Downlink TCP Retransmission Volume: {cluster_description.loc[group_name, 'Downlink TCP Retransmission Volume (Bytes)']:.2f} Bytes\")\n",
    "    print(f\"- Uplink TCP Retransmission Volume: {cluster_description.loc[group_name, 'Uplink TCP Retransmission Volume (Bytes)']:.2f} Bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretatiojn for the above modeling done using k-means clustering where k=3.  \n",
    "The **High-Performance Users** group enjoys the best network experience, with very low latency and moderate throughput. Their average downlink round-trip time (41.58 ms) and uplink round-trip time (4.73 ms) indicate a responsive connection, making tasks like browsing and real-time applications smooth. While their throughput is not as high as other groups (1046.69 kbps downlink and 104.89 kbps uplink), the network reliability is notable, as seen in relatively low TCP retransmission volumes. This group likely experiences a stable connection ideal for moderate usage and applications that prioritize low latency.\n",
    "\n",
    "The **Low-Performance Users** group, despite its name, actually enjoys very high throughput. With an average downlink throughput of 22036.65 kbps and uplink throughput of 965.12 kbps, these users are likely engaging in bandwidth-intensive activities such as streaming or downloading large files. However, the higher round-trip times (57.28 ms downlink and 13.13 ms uplink) and higher TCP retransmission volumes suggest occasional instability, which could lead to interruptions or buffering during their usage. This group might experience a powerful connection but with some inconsistencies.\n",
    "\n",
    "The **Moderate-Performance Users** fall in between the other two groups in terms of performance. They have higher latency (64.84 ms downlink and 13.35 ms uplink) and slightly lower throughput than the Low-Performance group, with an average downlink throughput of 18977.60 kbps and uplink throughput of 620.45 kbps. However, their significantly higher TCP retransmission volumes indicate that they might be facing more frequent packet loss, leading to a potentially less reliable connection. This group likely experiences a decent connection but may encounter issues when engaging in more demanding network activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally  \n",
    "We are going to create centroids which are important for the subsequent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids of Experience Clusters (Original Scale):\n",
      "                            Average Downlink Round-Trip Time (ms)  \\\n",
      "Cluster Name                                                        \n",
      "High-Performance Users                                  41.578110   \n",
      "Moderate-Performance Users                              64.824493   \n",
      "Low-Performance Users                                   57.291294   \n",
      "\n",
      "                            Average Uplink Round-Trip Time (ms)  \\\n",
      "Cluster Name                                                      \n",
      "High-Performance Users                                 4.730660   \n",
      "Moderate-Performance Users                            13.341740   \n",
      "Low-Performance Users                                 13.139212   \n",
      "\n",
      "                            Average Downlink Throughput (kbps)  \\\n",
      "Cluster Name                                                     \n",
      "High-Performance Users                             1047.174053   \n",
      "Moderate-Performance Users                        18969.910903   \n",
      "Low-Performance Users                             22042.073580   \n",
      "\n",
      "                            Average Uplink Throughput (kbps)  \\\n",
      "Cluster Name                                                   \n",
      "High-Performance Users                            104.954769   \n",
      "Moderate-Performance Users                        620.304212   \n",
      "Low-Performance Users                             965.082266   \n",
      "\n",
      "                            Downlink TCP Retransmission Volume (Bytes)  \\\n",
      "Cluster Name                                                             \n",
      "High-Performance Users                                    5.382487e+05   \n",
      "Moderate-Performance Users                                3.932814e+06   \n",
      "Low-Performance Users                                     6.887132e+05   \n",
      "\n",
      "                            Uplink TCP Retransmission Volume (Bytes)  \n",
      "Cluster Name                                                          \n",
      "High-Performance Users                                  20255.197323  \n",
      "Moderate-Performance Users                              82241.033541  \n",
      "Low-Performance Users                                   19465.627019  \n",
      "\n",
      "Centroid Experience DataFrame saved to: c:\\Users\\Beab\\Desktop\\Kifiya AIM\\Investor-feasibility-analysis\\notebooks\\centroid_experience.csv\n",
      "\n",
      "Cluster Descriptions (Averages of Experience Metrics):\n",
      "                            Average Downlink Round-Trip Time (ms)  \\\n",
      "Experience Group Name                                               \n",
      "High-Performance Users                                  41.578110   \n",
      "Low-Performance Users                                   57.281174   \n",
      "Moderate-Performance Users                              64.838950   \n",
      "\n",
      "                            Average Uplink Round-Trip Time (ms)  \\\n",
      "Experience Group Name                                             \n",
      "High-Performance Users                                 4.730363   \n",
      "Low-Performance Users                                 13.134860   \n",
      "Moderate-Performance Users                            13.351035   \n",
      "\n",
      "                            Average Downlink Throughput (kbps)  \\\n",
      "Experience Group Name                                            \n",
      "High-Performance Users                             1046.690679   \n",
      "Low-Performance Users                             22036.653552   \n",
      "Moderate-Performance Users                        18977.601663   \n",
      "\n",
      "                            Average Uplink Throughput (kbps)  \\\n",
      "Experience Group Name                                          \n",
      "High-Performance Users                            104.889182   \n",
      "Low-Performance Users                             965.117552   \n",
      "Moderate-Performance Users                        620.447024   \n",
      "\n",
      "                            Downlink TCP Retransmission Volume (Bytes)  \\\n",
      "Experience Group Name                                                    \n",
      "High-Performance Users                                    5.383542e+05   \n",
      "Low-Performance Users                                     6.887798e+05   \n",
      "Moderate-Performance Users                                3.930157e+06   \n",
      "\n",
      "                            Uplink TCP Retransmission Volume (Bytes)  \n",
      "Experience Group Name                                                 \n",
      "High-Performance Users                                  20255.823332  \n",
      "Low-Performance Users                                   19446.066409  \n",
      "Moderate-Performance Users                              82261.171706  \n",
      "\n",
      "High-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 41.58 ms\n",
      "- Average Uplink Round-Trip Time: 4.73 ms\n",
      "- Average Downlink Throughput: 1046.69 kbps\n",
      "- Average Uplink Throughput: 104.89 kbps\n",
      "- Downlink TCP Retransmission Volume: 538354.19 Bytes\n",
      "- Uplink TCP Retransmission Volume: 20255.82 Bytes\n",
      "\n",
      "Low-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 57.28 ms\n",
      "- Average Uplink Round-Trip Time: 13.13 ms\n",
      "- Average Downlink Throughput: 22036.65 kbps\n",
      "- Average Uplink Throughput: 965.12 kbps\n",
      "- Downlink TCP Retransmission Volume: 688779.82 Bytes\n",
      "- Uplink TCP Retransmission Volume: 19446.07 Bytes\n",
      "\n",
      "Moderate-Performance Users:\n",
      "This group of users tends to have the following network experience characteristics:\n",
      "- Average Downlink Round-Trip Time: 64.84 ms\n",
      "- Average Uplink Round-Trip Time: 13.35 ms\n",
      "- Average Downlink Throughput: 18977.60 kbps\n",
      "- Average Uplink Throughput: 620.45 kbps\n",
      "- Downlink TCP Retransmission Volume: 3930156.80 Bytes\n",
      "- Uplink TCP Retransmission Volume: 82261.17 Bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame\n",
    "\n",
    "# Select relevant experience metrics with descriptive names\n",
    "experience_metrics_descriptive = {\n",
    "    'Avg RTT DL (ms)': 'Average Downlink Round-Trip Time (ms)',\n",
    "    'Avg RTT UL (ms)': 'Average Uplink Round-Trip Time (ms)', \n",
    "    'Avg Bearer TP DL (kbps)': 'Average Downlink Throughput (kbps)',\n",
    "    'Avg Bearer TP UL (kbps)': 'Average Uplink Throughput (kbps)',\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'Downlink TCP Retransmission Volume (Bytes)',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'Uplink TCP Retransmission Volume (Bytes)'\n",
    "}\n",
    "\n",
    "# Drop rows with missing values in the selected columns\n",
    "df_experience = df_cleaned[list(experience_metrics_descriptive.keys())].dropna()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "experience_metrics_scaled = scaler.fit_transform(df_experience)\n",
    "\n",
    "# Convert scaled data back to a DataFrame for reference\n",
    "df_experience_scaled = pd.DataFrame(experience_metrics_scaled, columns=experience_metrics_descriptive.values())\n",
    "\n",
    "# Perform k-means clustering with k=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_experience_scaled['Experience Group'] = kmeans.fit_predict(experience_metrics_scaled)\n",
    "\n",
    "# Add the cluster labels to the original DataFrame with more descriptive names\n",
    "cluster_names = {\n",
    "    0: \"High-Performance Users\",\n",
    "    1: \"Moderate-Performance Users\",\n",
    "    2: \"Low-Performance Users\"\n",
    "}\n",
    "\n",
    "df_experience_scaled['Experience Group Name'] = df_experience_scaled['Experience Group'].map(cluster_names)\n",
    "df_cleaned['Experience Group Name'] = df_experience_scaled['Experience Group Name']\n",
    "\n",
    "# Retrieve the centroids in the scaled space\n",
    "centroids_scaled = kmeans.cluster_centers_\n",
    "\n",
    "# Inverse transform the centroids to the original scale\n",
    "centroids_original = scaler.inverse_transform(centroids_scaled)\n",
    "\n",
    "# Create a DataFrame to store centroids with descriptive cluster names\n",
    "centroid_experience = pd.DataFrame(centroids_original, columns=experience_metrics_descriptive.values())\n",
    "centroid_experience['Cluster Name'] = [cluster_names[i] for i in range(len(centroids_original))]\n",
    "\n",
    "# Set 'Cluster Name' as the index for easier referencing\n",
    "centroid_experience.set_index('Cluster Name', inplace=True)\n",
    "\n",
    "# Display the centroid DataFrame\n",
    "print(\"Centroids of Experience Clusters (Original Scale):\")\n",
    "print(centroid_experience)\n",
    "\n",
    "# Save the centroid_experience DataFrame to a CSV file\n",
    "file_path = 'centroid_experience.csv'\n",
    "centroid_experience.to_csv(file_path, index=True)\n",
    "\n",
    "# Display the path to the saved file\n",
    "print(f\"\\nCentroid Experience DataFrame saved to: {os.path.abspath(file_path)}\")\n",
    "\n",
    "# Brief description of each cluster based on the average of experience metrics\n",
    "cluster_description = df_cleaned.groupby('Experience Group Name')[list(experience_metrics_descriptive.keys())].mean()\n",
    "cluster_description.columns = experience_metrics_descriptive.values()  # Update column names to descriptive\n",
    "\n",
    "# Print the cluster descriptions\n",
    "print(\"\\nCluster Descriptions (Averages of Experience Metrics):\")\n",
    "print(cluster_description)\n",
    "\n",
    "# Provide a brief interpretation of the clusters with descriptive labels\n",
    "for group_name in cluster_description.index:\n",
    "    print(f\"\\n{group_name}:\")\n",
    "    print(\"This group of users tends to have the following network experience characteristics:\")\n",
    "    print(f\"- Average Downlink Round-Trip Time: {cluster_description.loc[group_name, 'Average Downlink Round-Trip Time (ms)']:.2f} ms\")\n",
    "    print(f\"- Average Uplink Round-Trip Time: {cluster_description.loc[group_name, 'Average Uplink Round-Trip Time (ms)']:.2f} ms\")\n",
    "    print(f\"- Average Downlink Throughput: {cluster_description.loc[group_name, 'Average Downlink Throughput (kbps)']:.2f} kbps\")\n",
    "    print(f\"- Average Uplink Throughput: {cluster_description.loc[group_name, 'Average Uplink Throughput (kbps)']:.2f} kbps\")\n",
    "    print(f\"- Downlink TCP Retransmission Volume: {cluster_description.loc[group_name, 'Downlink TCP Retransmission Volume (Bytes)']:.2f} Bytes\")\n",
    "    print(f\"- Uplink TCP Retransmission Volume: {cluster_description.loc[group_name, 'Uplink TCP Retransmission Volume (Bytes)']:.2f} Bytes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
